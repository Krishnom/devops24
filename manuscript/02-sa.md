# TODO

- [X] Code
- [ ] Write
- [ ] Code review kops
- [ ] Code review minikube
- [ ] Code review Docker for Mac/Windows
- [ ] Code review minishift
- [ ] Code review GKE
- [ ] Code review Azure
- [ ] Code review EKS
- [ ] Code review Rancher
- [ ] Compare platforms
- [ ] Text review
- [ ] Diagrams
- [ ] Gist
- [ ] Review the title
- [ ] Proofread
- [ ] Add to slides
- [ ] Publish on TechnologyConversations.com
- [ ] Add to Book.txt
- [ ] Publish on LeanPub.com

# Service Accounts

T> Humans are not the only ones who operate a Kubernetes cluster. Processes in container often need to invoke Kube API as well. When using RBAC for authentication, we need to decide which users will have permissions to perform certain actions. The same holds true for the processes running in containers.

When we (humans) try to access a Kubernetes cluster with RBAC enabled, we are authenticated as users. Our username provides an identity API server uses to decide whether we are allowed to perform certain actions. Processes running inside containers might also need to access the API. In such cases, they are authenticated as a specific ServiceAccount.

ServiceAccounts are the mechanism that will allow us to grant permissions to processes running inside containers. In many ways, ServiceAccounts are very similar to RBAC users or groups. With humans we use RoleBindings and ClusterRoleBindings to connect users and groups to Roles and ClusterRoles. When working with processes, the main difference is in the name and the scope. Instead of users or groups, we'll create ServiceAccounts which we'll bind to roles. Unlike users that are global, our ServiceAccounts will be tied to specific Namespaces.

We won't go into more theory. Instead, we'll try to learn different aspects of ServiceAccounts through hands-on examples.

## Creating A Cluster

We'll start the hands-on walk-through by entering the directory where we cloned the `vfarcic/k8s-specs` repository.

W> ## A note to Windows users
W>
W> Please run all the examples from *GitBash* (installed through *Git*). That way the commands you'll see throughout the book will be same as those that should be executed on *MacOS* or any *Linux* distribution. If you're using Hyper-V instead of VirtualBox, you may need to run the *GitBash* window as an Administrator.

```bash
cd k8s-specs
```

Next, we'll have to have a cluster which we can use to experiment with ServiceAccounts. The requirements are the same as those we used in the previous chapter. We'll need **Kubernetes version 1.9** or higher as well as **nginx Ingress Controller**, **RBAC**, and a **default StorageClass**. Please continue using the cluster you created in the previous chapter, if you didn't destroy it. Otherwise, it should be fairly fast to create a new one. For your convenience, the Gists and the specs we used before is available here as well.

* [TODO](TODO) **minikube** with 2 CPUs, 2GB RAM, and with `ingress`, `storage-provisioner`, and `default-storageclass` addons enabled
* [TODO](TODO) **Docker for Mac** with 2 CPUs, 2GB RAM, and with nginx Ingress
* [TODO](TODO) **kops in AWS** with three t2.small masters and two t2.medium nodes spread in three availability zones, and with nginx Ingress (assumes prerequisites set through [Appendix B](#appendix-b)).
* [TODO](TODO) **minishift** TODO
* [TODO](TODO) **GKE** TODO
* [TODO](TODO) **Azure** TODO
* [TODO](TODO) **EKS** TODO
* [TODO](TODO) **Rancher** TODO

## Jenkins With Kubernetes

We'll start by creating the same Jenkins StatefulSet we used in the previous chapter. Once it's up-and-running, we'll try to use the [Jenkins Kubernetes plugin](TODO). If we're successful, we'll have a tool which could be used to execute continuous delivery or deployment tasks inside a Kubernetes cluster.

```bash
cat sa/jenkins-no-sa.yml
```

We won't go through the definition since it is (almost) the same as the one we used in the previous chapter. There's no mystery that has to be revealed so we'll move on and create the resources defined in that YAML.

```bash
kubectl create \
    -f sa/jenkins-no-sa.yml \
    --record --save-config

kubectl -n jenkins \
    rollout status sts master
```

The latter command should tell us when the rollout is complete and Jenkins is ready for us.

Next, we'll discover the DNS (or IP) of the load balancer and open Jenkins UI.

```bash
CLUSTER_DNS=$(kubectl -n jenkins \
    get ing master \
    -o jsonpath="{.status.loadBalancer.ingress[0].hostname}")

open "http://$CLUSTER_DNS/jenkins"
```

Now we need to go through the setup wizard. It's a boring process that we already did before and I'm sure you're not thrilled with the prospects of going through it again. However, we're still missing knowledge and tools that will allow us to automate the process so we'll have to go through it again.

The first step is to get the initial admin password.

```bash
kubectl -n jenkins \
    exec master-0 -it -- \
    cat /var/jenkins_home/secrets/initialAdminPassword
```

Please copy the output and paste it into Jenkins UI *Administrator password* field. Click the *Continue* button, followed with a click to *Install suggested plugins* button. Fill in the *Create First Admin User* fields and press the *Save and Finish* button. Finally, Jenkins is ready and only a click away. Please press the *Start using Jenkins* button.

If we are to use the [Kubernetes plugin](TODO), we need to install it first. So, we'll open the available plugins section of the plugin manager screen.

```bash
open "http://$CLUSTER_DNS/jenkins/pluginManager/available"
```

Type *Kubernetes* in the *Filter* field and select the checkbox next to it.

Since we are already in the plugin manager screen, we might just as well install BlueOcean as well and make Jenkins prettier.

Type *BlueOcean* in the *Filter* field and select the checkbox next to it.

Now that we selected the plugins we want, the next step is to install them. Please click the *Install without restart* button and wait until all the plugins (and their dependencies) are installed.

We are not yet finished. WE still need to configure the newly installed Kubernetes plugin.

```bash
open "http://$CLUSTER_DNS/jenkins/configure"
```

The plugin adds Kubernetes as yet another *Cloud* provider. Please click the *Add a new cloud* drop-down list in the *Cloud* section, and select *Kubernetes*. The cloud section should be somewhere close to the bottom of the screen.

Now that we added Kubernetes as a Cloud provider, we should confirm that it actually works. Please click the *Test Connection* button.

Unless you forgot to unable RBAC in your cluster, the output should be similar to the one that follows.

```
Error testing connection : Failure executing: GET at: https://kubernetes.default.svc/api/v1/namespaces/jenkins/pods. Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. pods is forbidden: User "system:serviceaccount:jenkins:default" cannot list pods in the namespace "jenkins".
```

API server rejected our request to list the Pods in the `jenkins` Namespace. Such a reaction makes perfect sense. If any process in any container could do request anything from the API, our security efforts would be useless. What would be the point of trying to restrict users (humans) if all it takes is to create a single Pod that sends a request to the API server. It rightfully denied our request to list the Pods.

Just as a username provides a sort of identity to humans, a ServiceAccount is an identity for all the processes that run in containers. Since we did not specify any ServiceAccount for the Pod where Jenkins is running, Kubernetes assigned one for us. The Pod is authenticated as `default` account which happens to be bound to roles that give almost no permissions. In other word, if we do not define a ServiceAccount for a Pod, it'll be associated with the ServiceAccount `default`, and the processes inside that Pod will not be able to requests almost anything from the API server.

A `default` ServiceAccount is create for every Namespace in the cluster. It is, in a way, similar to the default StorageClass. If a Pod does not have a ServiceAccount, it'll get the `default`. The `default` ServiceAccount has very limited privileges and it cannot do almost anything. We can bind more permissive role to the `default` ServiceAccount but that would be a very uncommon solution to the problem.

We need to associate Jenkins process with an entity that has more permissions. As a minimum, we need to be able to list the Pod in the `jenkins` Namespace. Since we do not yet know how to create ServiceAccounts, we'll try to solve our problem by associating the process with our own administrative user. We'll let the API server know that we'll let Jenkins identify as us.

Please click the *Add* drop-down list in the *Credentials* section and select *Jenkins*.

We should type our username and password but we are probably having an identity crisis. The chances are that you do not know the password. You might not even know your username. If you created the cluster with let's say kops, it created a new username for you and placed the information in `kubectl` config. It never even informed you about your user. Almost all other tools that help us create a cluster work in the same way. A user is created together with the cluster and added to `kubectl` config while leaving us oblivious of its existence.

If, on the other hand, someone gave you access to an existing cluster, you were probably asked to provide a user and a password and, in those cases, you might already know the credentials you need to use to access the cluster. We'll go with the safer option and blame it on forgetfulness.

We'll fetch your `username` from the `kubectl` config.

```bash
kubectl config view \
    -o jsonpath='{.users[?(@.name == "devops23.k8s.local-basic-auth")].user.username}'
```

Please copy the output and paste it into the *Username* field. 

We'll go back to the terminal to fetch the password as well.

```bash
kubectl config view \
    -o jsonpath='{.users[?(@.name == "devops23.k8s.local-basic-auth")].user.password}'
```

Please copy the output and paste it into the *Password* field.

Please type *kubernetes* in the remaining two fields (*ID* and *Description*) and click the *Add* button.

Now you're back in the *Kubernetes Cloud* section of the configuration. Select the newly created credentials and click the *Test Connection* button. This time, the output should confirm that the *Connection test* was *successful*.

We associated our own user with the Jenkins process. From the API server's perspective, both our local `kubectl` binary and the Jenkins process belong to the same user which happens to be an administrator. It does think that in both cases a human (you) is interacting with it. We'll change that later on when we try to associate Jenkins with a ServiceAccount. But, for now, Jenkins being a human is much better than not having permissions even to list the Pods in the `jenkins` Namespace.

We're almost done with the first attempt to make Jenkins communicate with the API server. The last thing missing is to type *http://master:8080/jenkins* in the *Jenkins URL* field. That way, soon-to-be-created Pods will communicate with Jenkins through the `master` service. If we left it intact, the communication would go through the load balancer and Jenkins' Ingress.

Please click the *Save* button.

Next, we'll create a simple job that should provide a final validation whether we configured Jenkins and Kubernetes plugin correctly.

Please click the *New Item* link in the left-hand menu, type *my-k8s-job* in the *item name* field, select *Pipeline* as the type, and click the *OK* button. You are inside a Pipeline job configuration screen and we are about to write a script.

Click the *Pipeline* tab and write the script that follows in the *Pipeline Script* field.

```groovy
podTemplate(
    label: 'kubernetes',
    containers: [
        containerTemplate(name: 'maven', image: 'maven:alpine', ttyEnabled: true, command: 'cat'),
        containerTemplate(name: 'golang', image: 'golang:alpine', ttyEnabled: true, command: 'cat')
    ]
) {
    node('kubernetes') {
        container('maven') {
            stage('build') {
                sh 'mvn --version'
            }
            stage('unit-test') {
                sh 'java -version'
            }
        }
        container('golang') {
            stage('deploy') {
                sh 'go version'
            }
        }
    }
}
```

The script is so simple that it should be self explanatory even if you never worked with Jenkins pipelines.

The `podTemplate` section defines two container templates. One container will be based on `maven` nad the other on `golang`. The two containers will form a Pod.

Further down, we're using the `podTemplate` labeled `kubernetes` as a node in which we defined a few stages with a few simple `sh` commands. The steps inside the `maven` container will only output Maven and Java versions. Similarly, the step in the `golang` container will output Go version.

The purpose of this job is not to do anything meaningful but only to confirm that Jenkins process has sufficient permissions to communicate with the API server, and it can create Pods, and that it can execute commands inside those Pods. The whole exercise is mostly a confirmation that we correctly configured the Kubernetes plugin.

Please click the *Save* button, followed with the *Open Blue Ocean* link from the left-hand menu. Let's run a build of the newly created job and see the effects and the results. Click the *Run* button and switch back to the terminal window.

```bash
kubectl -n jenkins get pods
```

A few moments later, the output of the `get pods` command should be as follows.

```
NAME              READY STATUS  RESTARTS AGE
jenkins-0         1/1   Running 0        13m
jenkins-slave-... 3/3   Running 0        12s
```

We can see that the build we're running created a new Pod with the name starting with `jenkins-slave-`. That Pod contains the two contains we defined in the job (`maven` and `golang`) as well as the additional third container Jenkins injected into the Pod definition. That container is in charge of establishing the communication between the newly created Pod and the master (`jenkins-0`).

Lat's take another look at the Pods in the `jenkins` Namespace.

```bash
kubectl -n jenkins get pods
```

If you executed the command the moment the Job finished executing, the output should be as follows.

```
NAME            READY STATUS      RESTARTS AGE
jenkins-0       1/1   Running     0        14m
jenkins-slave-* 0/3   Terminating 0        1m
```

Jenkins issued a request to the API server to delete the Pod. There's no reason for it to run forever. The moment Jenkins executed all the steps we defined in the job, the usefulness of the Pod disappeared. We call those Pods one-shot agents. Jenkins creates them, uses them as agents that do the work, and it destroys them when they're not needed any more.

We managed to configure Jenkins process to communicate with the API server and create Pods. Actually, we configured the process to have the same system-admin privileges as our user. Jenkins could do anything inside the cluster. It could even destroy system level Pods and bring the whole cluster down. Moreover, we already discussed that user accounts are for humans, not processes.

We'll delete `jenkins` Namespace and explore ServiceAccounts in our quest to enable and control the communication between API server and  processes running in containers.

```bash
kubectl delete ns jenkins
```

## With The `default` ServiceAccount

Jenkins might not be the best starting point in our exploration of ServiceAccounts. Too many things are happening out of our control. There's too much "magic" hidden behind Jenkins code. Instead, we'll start with something simpler. We'll run `kubectl` as a Pod. If we manage to make that work, we should have no problem applying the knowledge to Jenkins and MongoDB side-car.

Unfortunately, there is no `kubectl` official image (at least not in Docker Hub), so I built one. The definition is in the [vfarcic/kubectl](TODO) GitHub repository. Let's take a quick look.

```bash
curl https://raw.githubusercontent.com/vfarcic/kubectl/master/Dockerfile
```

The Dockerfile is so simple and uneventful that there's probably no need going through it. It's a `kubectl` binary in an `alpine` based image. Not more, not less.

Let's run it.

```bash
kubectl run kubectl \
    --image=vfarcic/kubectl \
    --restart=Never \
    sleep 10000
```

We should wait for a few moments until the image is pulled and the container that forms the Pod is running.

Let's start by checking out the `serviceAccount` entry in the specification.

```bash
kubectl get pod kubectl \
    -o jsonpath="{.spec.serviceAccount}"
```

The output is as follows.

```
default
```

Since we did not specify an ServiceAccount, the `default` one that was created with the Namaspace was assigned to the Pod automatically.

We might be able to dig a bit more infomation from within the `kubect` container.

```bash
kubectl exec -it kubectl -- sh
```

No matter which ServiceAccount is used, Kubernetes always mount a secret with the information about that account. The secret is mounted inside the `/var/run/secrets/kubernetes.io/serviceaccount` directory. 

```bash
cd /var/run/secrets/kubernetes.io/serviceaccount

ls -la
```

We entered into the secret's directory and list all the files. The output is as follows.

```
total 4
drwxrwxrwt 3 root root  140 Apr 12 14:38 .
drwxr-xr-x 3 root root 4096 Apr 12 14:38 ..
drwxr-xr-x 2 root root  100 Apr 12 14:38 ..4984_12_04_14_38_16.013593790
lrwxrwxrwx 1 root root   31 Apr 12 14:38 ..data -> ..4984_12_04_14_38_16.013593790
lrwxrwxrwx 1 root root   13 Apr 12 14:38 ca.crt -> ..data/ca.crt
lrwxrwxrwx 1 root root   16 Apr 12 14:38 namespace -> ..data/namespace
lrwxrwxrwx 1 root root   12 Apr 12 14:38 token -> ..data/token
```

We can see that it created three soft-links (`ca.crt`, `namespace`, and `token`) that point to a directory that contains the actual files. You should be able to guess what those files contain. The token and the certificate are used as authentication when communicating with the API server. The third file contains only the Namespace in which the Pod is running.

Let's try a very simple operation.

```bash
kubectl get pods
```

The output is as follows.

```
Error from server (Forbidden): pods is forbidden: User "system:serviceaccount:default:default" cannot list pods in the namespace "default"
```

We got a similar error message as when we tried to use Jenkins' Kubernetes plugin without any credentials. Once again we're faced with limited permissions bound to the `default` account. We'll change that soon. For now, we'll exit the container and remove the `kubectl` Pod.

```bash
exit

kubectl delete pod kubectl
```

We saw the limitations behind the `default` account. Next we'll try to overcome those limitations by creating our own ServiceAccounts.

## With ServiceAccount

```bash
kubectl get sa
```

```
NAME    SECRETS AGE
default 1       24m
```

```bash
cat sa/view.yml
```

```
apiVersion: v1
kind: ServiceAccount
metadata:
  name: view

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: view
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
- kind: ServiceAccount
  name: view
```

```bash
kubectl create \
    -f sa/view.yml \
    --record --save-config
```

```
serviceaccount "view" created
rolebinding "view" created
```

```bash
kubectl get sa
```

```
NAME    SECRETS AGE
default 1       27m
view    1       6s
```

```bash
kubectl describe sa view
```

```
Name:         view
Namespace:    default
Labels:       <none>
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"v1","kind":"ServiceAccount","metadata":{"annotations":{},"name":"view","namespace":"default"}}

                     kubernetes.io/change-cause=kubectl create --filename=sa/view.yml --record=true --save-config=true
Image pull secrets:  <none>
Mountable secrets:   view-token-292vm
Tokens:              view-token-292vm
Events:              <none>
```

```bash
kubectl describe rolebinding view
```

```
Name:         view
Labels:       <none>
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"rbac.authorization.k8s.io/v1beta1","kind":"RoleBinding","metadata":{"annotations":{},"name":"view","namespace":"default"},"roleRef":{"ap...
              kubernetes.io/change-cause=kubectl create --filename=sa/view.yml --record=true --save-config=true
Role:
  Kind:  ClusterRole
  Name:  view
Subjects:
  Kind            Name  Namespace
  ----            ----  ---------
  ServiceAccount  view
```

```bash
cat sa/kubectl-view.yml
```

```
apiVersion: v1
kind: Pod
metadata:
  name: test
spec:
  serviceAccountName: view
  containers:
  - name: test
    image: alpine:3.5
    command: ["sleep"]
    args: ["100000"]
```

```bash
kubectl create \
    -f sa/kubectl-view.yml \
    --record --save-config

kubectl describe pod kubectl
```

```
Name:         kubectl
Namespace:    default
Node:         ip-172-20-103-156.us-east-2.compute.internal/172.20.103.156
Start Time:   Thu, 12 Apr 2018 16:50:51 +0200
Labels:       <none>
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"name":"kubectl","namespace":"default"},"spec":{"containers":[{"args":["100000"],"command"...
              kubernetes.io/change-cause=kubectl create --filename=sa/kubectl-view.yml --record=true --save-config=true
              kubernetes.io/limit-ranger=LimitRanger plugin set: cpu request for container kubectl
Status:       Running
IP:           100.96.2.8
Containers:
  kubectl:
    Container ID:  docker://4e3b3dff00be4a77d9f45f5411677b4c3c0fa2d18f901d75d69d12d711fa5048
    Image:         vfarcic/kubectl
    Image ID:      docker-pullable://vfarcic/kubectl@sha256:023246835010501391e7851673eb9e08d068b29dd215abdb17df8ae9b7cddee0
    Port:          <none>
    Command:
      sleep
    Args:
      100000
    State:          Running
      Started:      Thu, 12 Apr 2018 16:50:56 +0200
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:        100m
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from view-token-292vm (ro)
Conditions:
  Type           Status
  Initialized    True 
  Ready          True 
  PodScheduled   True 
Volumes:
  view-token-292vm:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  view-token-292vm
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.alpha.kubernetes.io/notReady:NoExecute for 300s
                 node.alpha.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason                 Age   From                                                   Message
  ----    ------                 ----  ----                                                   -------
  Normal  Scheduled              8s    default-scheduler                                      Successfully assigned kubectl to ip-172-20-103-156.us-east-2.compute.internal
  Normal  SuccessfulMountVolume  8s    kubelet, ip-172-20-103-156.us-east-2.compute.internal  MountVolume.SetUp succeeded for volume "view-token-292vm"
  Normal  Pulling                7s    kubelet, ip-172-20-103-156.us-east-2.compute.internal  pulling image "vfarcic/kubectl"
  Normal  Pulled                 3s    kubelet, ip-172-20-103-156.us-east-2.compute.internal  Successfully pulled image "vfarcic/kubectl"
  Normal  Created                3s    kubelet, ip-172-20-103-156.us-east-2.compute.internal  Created container
  Normal  Started                3s    kubelet, ip-172-20-103-156.us-east-2.compute.internal  Started container
```

```bash
kubectl exec -it kubectl -- sh

kubectl get pods
```

```
NAME READY STATUS  RESTARTS AGE
test 1/1   Running 0        55s
```

```bash
kubectl run new-test \
    --image=alpine \
    --restart=Never \
    sleep 10000
```

```
Error from server (Forbidden): pods is forbidden: User "system:serviceaccount:default:view" cannot create pods in the namespace "default"
```

```bash
exit

kubectl delete -f sa/kubectl-view.yml
```

```
pod "kubectl" deleted
```

```bash
cat sa/pods.yml
```

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: pods-all
  namespace: test1

---

kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: pods-all
  namespace: test1
rules:
- apiGroups: [""]
  resources: ["pods", "pods/exec", "pods/log"]
  verbs: ["*"]

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: pods-all
  namespace: test1
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: pods-all
subjects:
- kind: ServiceAccount
  name: pods-all
```

```bash
kubectl create -f sa/pods.yml \
    --record --save-config

kubectl create ns test2

cat sa/kubectl-test1.yml
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kubectl
  namespace: test1
spec:
  serviceAccountName: pods-all
  containers:
  - name: kubectl
    image: vfarcic/kubectl
    command: ["sleep"]
    args: ["100000"]
```

```bash
kubectl create \
    -f sa/kubectl-test1.yml \
    --record --save-config

kubectl -n test1 exec -it kubectl -- sh

kubectl get pods
```

```
NAME    READY STATUS  RESTARTS AGE
kubectl 1/1   Running 0        5m
```

```bash
kubectl run new-test \
    --image=alpine \
    --restart=Never \
    sleep 10000
```

```
pod "new-test" created
```

```bash
kubectl get pods
```

```
NAME     READY STATUS  RESTARTS AGE
kubectl  1/1   Running 0        6m
new-test 1/1   Running 0        17s
```

```bash
kubectl run new-test --image=alpine sleep 10000
```

```
Error from server (Forbidden): deployments.extensions is forbidden: User "system:serviceaccount:test1:pods-all" cannot create deployments.extensions in the namespace "test1"
```

```bash
kubectl -n test2 get pods
```

```
Error from server (Forbidden): pods is forbidden: User "system:serviceaccount:test1:pods-all" cannot list pods in the namespace "test2"
```

The ServiceAccount was created in the `test1` Namespace. Only the Pods created in the same Namespace can be attached to the `pods-all` ServiceAccount. However, in this case, the important thing to note is that the RoleBinding that gives us the permissions to, for example, retrieve the Pods, exists only the in `test1` Namespace. The moment we tried to retrieve the Pods from a different Namespace, the API server responded with an error notifying us that we do not have permissions to `list pods in the namespace "test2"`.

T> While user accounts are global, ServiceAccounts are namespaced. After all, a human user is almost always invoking the API from outside the cluster while the processes inside containers are always inside Pods which are inside Namespaces.

TODO: Continue writing

```bash
exit

kubectl delete -f sa/kubectl-test1.yml

cat sa/pods-all.yml
```

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: pods-all
  namespace: test1

---

kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: pods-all
  namespace: test1
rules:
- apiGroups: [""]
  resources: ["pods", "pods/exec", "pods/log"]
  verbs: ["*"]

---

kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: pods-all
  namespace: test2
rules:
- apiGroups: [""]
  resources: ["pods", "pods/exec", "pods/log"]
  verbs: ["*"]

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: pods-all
  namespace: test1
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: pods-all
subjects:
- kind: ServiceAccount
  name: pods-all

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: pods-all
  namespace: test2
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: pods-all
subjects:
- kind: ServiceAccount
  name: pods-all
  namespace: test1
```

```bash
kubectl apply -f sa/pods-all.yml \
    --record

cat sa/kubectl-test2.yml
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kubectl
  namespace: test1
spec:
  serviceAccountName: pods-all
  containers:
  - name: kubectl
    image: vfarcic/kubectl
    command: ["sleep"]
    args: ["100000"]
```

```bash
kubectl create \
    -f sa/kubectl-test2.yml \
    --record --save-config

kubectl -n test1 exec -it kubectl -- sh

kubectl get pods
```

```
NAME     READY STATUS  RESTARTS AGE
kubectl  1/1   Running 0        22s
new-test 1/1   Running 0        2m
```

```bash
kubectl -n test2 get pods
```

```
No resources found.
```

```bash
kubectl -n test2 \
    run new-test \
    --image=alpine \
    --restart=Never \
    sleep 10000
```

```
pod "new-test" created
```

```bash
kubectl -n test2 get pods
```

```
NAME     READY STATUS  RESTARTS AGE
new-test 1/1   Running 0        18s
```

```bash
kubectl -n default get pods
```

```
Error from server (Forbidden): pods is forbidden: User "system:serviceaccount:test1:pods-all" cannot list pods in the namespace "default"
```

```bash
kubectl -n kube-system get pods
```

```
Error from server (Forbidden): pods is forbidden: User "system:serviceaccount:test1:pods-all" cannot list pods in the namespace "kube-system"
```

```bash
exit

kubectl delete ns test1 test2
```

```
namespace "test1" deleted
namespace "test2" deleted
```

## Jenkins w/Kubernetes (again)

```bash
cat sa/jenkins.yml
```

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: jenkins

---

apiVersion: v1
kind: Namespace
metadata:
  name: build

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: master
  namespace: jenkins

---

kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: master
  namespace: build
rules:
- apiGroups: [""]
  resources: ["pods", "pods/exec", "pods/log"]
  verbs: ["*"]
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: master
  namespace: build
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: master
subjects:
- kind: ServiceAccount
  name: master
  namespace: jenkins

---

apiVersion: v1
kind: Service
metadata:
  name: master
  namespace: jenkins
spec:
  selector:
    app: master
  ports:
  - name: http
    port: 80
    targetPort: 8080
    protocol: TCP
  - name: agent
    port: 50000
    protocol: TCP
  clusterIP: None

---

apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: master
  namespace: jenkins
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/proxy-body-size: 50m
    nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    ingress.kubernetes.io/ssl-redirect: "false"
    ingress.kubernetes.io/proxy-body-size: 50m
    ingress.kubernetes.io/proxy-request-buffering: "off"
spec:
  rules:
  - http:
      paths:
      - path: /jenkins
        backend:
          serviceName: master
          servicePort: 80

---

apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: master
  namespace: jenkins
  labels:
    app: master
spec:
  serviceName: master
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      name: master
      labels:
        app: master
    spec:
      terminationGracePeriodSeconds: 10
      serviceAccountName: master
      containers:
      - name: master
        image: jenkins/jenkins:lts-alpine
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
        - containerPort: 50000
        resources:
          limits:
            cpu: 1
            memory: 1Gi
          requests:
            cpu: 0.5
            memory: 500Mi
        env:
        - name: JENKINS_OPTS
          value: --prefix=/jenkins
        - name: LIMITS_MEMORY
          valueFrom:
            resourceFieldRef:
              resource: limits.memory
              divisor: 1Mi
        - name: JAVA_OPTS
          value: -Xmx$(LIMITS_MEMORY)m -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85
        volumeMounts:
        - name: master-home
          mountPath: /var/jenkins_home
        livenessProbe:
          httpGet:
            path: /jenkins/login
            port: 8080
          initialDelaySeconds: 60
          timeoutSeconds: 5
          failureThreshold: 12 # ~2 minutes
        readinessProbe:
          httpGet:
            path: /jenkins/login
            port: 8080
          initialDelaySeconds: 60
          timeoutSeconds: 5
          failureThreshold: 12 # ~2 minutes
      securityContext:
        fsGroup: 1000
  volumeClaimTemplates:
  - metadata:
      name: master-home
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 2Gi
```

```bash
kubectl create \
    -f sa/jenkins.yml \
    --record --save-config
```

```
namespace "jenkins" created
serviceaccount "master" created
role "master" created
rolebinding "master" created
service "master" created
ingress "master" created
statefulset "master" created
```

```bash
kubectl -n jenkins \
    rollout status sts master
```

```
    rollout status sts master
statefulset rolling update complete 1 pods at revision master-55b49b8867...
```

```bash
open "http://$CLUSTER_DNS/jenkins"

kubectl -n jenkins \
    exec master-0 -it -- \
    cat /var/jenkins_home/secrets/initialAdminPassword

# Copy the output and paste it into Jenkins UI *Administrator password* field

# Click the *Continue* button

# Click the *Install suggested plugins* button

# Fill in the *Create First Admin User* fields

# Click the *Save and Finish* button

# Click the *Start using Jenkins* button

open "http://$CLUSTER_DNS/jenkins/pluginManager/available"

# Type *Kubernetes* in the *Filter* field

# Select *Kubernetes* checkbox

# Type *BlueOcean* in the *Filter* field

# Select *BlueOcean* checkbox

# Click the *Install without restart* button

open "http://$CLUSTER_DNS/jenkins/configure"

# Click the *Add a new cloud* drop-down list in the *Cloud* section

# Select *Kubernetes*

# Type *build* in the *Kubernetes Namespace* field

# Click the *Test Connection* button
```

```
Connection test successful
```

```bash
# Type *http://master.jenkins:8080/jenkins* in the *Jenkins URL* field

# Click the *Save* button

# Click the *New Item* link in the left-hand menu

# Type *my-k8s-job* in the *item name* field

# Select *Pipeline* as the type

# Click the *OK* button

# Click the *Pipeline* tab

# Write the script that follows in the *Pipeline Script* field
```

```groovy
podTemplate(
    label: 'kubernetes',
    containers: [
        containerTemplate(name: 'maven', image: 'maven:alpine', ttyEnabled: true, command: 'cat'),
        containerTemplate(name: 'golang', image: 'golang:alpine', ttyEnabled: true, command: 'cat')
    ]
) {
    node('kubernetes') {
        container('maven') {
            stage('build') {
                sh 'mvn --version'
            }
            stage('unit-test') {
                sh 'java -version'
            }
        }
        container('golang') {
            stage('deploy') {
                sh 'go version'
            }
        }
    }
}
```

```bash
# Click the *Save* button

# Click the *Open Blue Ocean* link from the left-hand menu

# Click the *Run* button

kubectl -n build get pods
```

```
NAME                      READY STATUS  RESTARTS AGE
jenkins-slave-6d8nx-fv3kv 3/3   Running 0        5s
```

```bash
kubectl -n build get pods
```

```
NAME                      READY STATUS      RESTARTS AGE
jenkins-slave-6d8nx-fv3kv 3/3   Terminating 0        32s
```

```bash
kubectl delete ns jenkins build
```

## Mongo

```bash
cat sa/go-demo-3.yml
```

```yaml

```

```bash
kubectl create \
    -f sa/go-demo-3.yml \
    --record --save-config
```

```
namespace "go-demo-3" created
ingress "api" created
serviceaccount "db" created
role "db" created
rolebinding "db" created
statefulset "db" created
service "db" created
deployment "api" created
service "api" created
```

```bash
kubectl -n go-demo-3 \
    get pods
```

```
NAME                 READY STATUS  RESTARTS AGE
api-649cfb4987-chkcf 1/1   Running 1        1m
api-649cfb4987-m6fms 1/1   Running 1        1m
api-649cfb4987-sgmtg 1/1   Running 1        1m
db-0                 2/2   Running 0        1m
db-1                 2/2   Running 0        1m
db-2                 2/2   Running 0        54s
```

```bash
kubectl -n go-demo-3 \
    logs db-0 -c db-sidecar

# Output is too big to display

kubectl delete ns go-demo-3
```

## What Now?

```bash
kops delete cluster \
    --name $NAME \
    --yes

aws s3api delete-bucket \
    --bucket $BUCKET_NAME
```
